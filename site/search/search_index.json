{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to StableRLS's documentation! StableRLS is a reinforcement learning library focused on stability and reliability in training and deployment. \ud83d\ude80 Getting Started Installation - Install StableRLS and dependencies Port Creation - Create communication ports Configuration - Configure your environment \ud83d\udd27 Components & Tools Config Reader - Configuration file handling Create FMU - Functional Mock-up Unit creation FMU Tools - Tools for working with FMUs Gym FMU - OpenAI Gym integration \ud83d\udcda Examples & Learning Tutorial Notebooks - Interactive Jupyter notebooks with examples \ud83d\udcd6 Reference API Reference - Complete API documentation Contributing - How to contribute to StableRLS","title":"Home"},{"location":"#welcome-to-stablerlss-documentation","text":"StableRLS is a reinforcement learning library focused on stability and reliability in training and deployment.","title":"Welcome to StableRLS's documentation!"},{"location":"#getting-started","text":"Installation - Install StableRLS and dependencies Port Creation - Create communication ports Configuration - Configure your environment","title":"\ud83d\ude80 Getting Started"},{"location":"#components-tools","text":"Config Reader - Configuration file handling Create FMU - Functional Mock-up Unit creation FMU Tools - Tools for working with FMUs Gym FMU - OpenAI Gym integration","title":"\ud83d\udd27 Components &amp; Tools"},{"location":"#examples-learning","text":"Tutorial Notebooks - Interactive Jupyter notebooks with examples","title":"\ud83d\udcda Examples &amp; Learning"},{"location":"#reference","text":"API Reference - Complete API documentation Contributing - How to contribute to StableRLS","title":"\ud83d\udcd6 Reference"},{"location":"notebooks/overview/","text":"Examples Tutorial Notebooks The following Jupyter notebooks provide hands-on examples and tutorials. You can view and download them directly: \ud83d\udcd3 00-GetStarted.ipynb Basic introduction to StableRLS - Learn the fundamentals of StableRLS - Set up your first environment - Run a basic simulation \ud83d\udcd3 01-Reward_Function.ipynb Understanding and customizing reward functions - Learn how reward functions work - Create custom reward functions - Optimize training performance \ud83d\udcd3 02-Advanced_Usage.ipynb Advanced features and configurations - Explore advanced configuration options - Use advanced simulation features - Integrate with external tools \ud83d\udcd3 03-Customising_Actions_Observations.ipynb How to customize the action and observation spaces - Define custom action spaces - Configure observation spaces - Handle complex state representations \ud83d\udcd3 04-Customising_Timing.ipynb Timing configuration and control - Configure simulation timing - Handle time-based events - Synchronize with real-time systems Running the Notebooks To run these notebooks locally: Ensure you have Jupyter installed: pip install jupyter Navigate to the notebooks directory: cd docs/notebooks/ Start Jupyter: jupyter notebook Open any notebook file (.ipynb) in the Jupyter interface","title":"Overview"},{"location":"notebooks/overview/#examples","text":"","title":"Examples"},{"location":"notebooks/overview/#tutorial-notebooks","text":"The following Jupyter notebooks provide hands-on examples and tutorials. You can view and download them directly:","title":"Tutorial Notebooks"},{"location":"notebooks/overview/#00-getstartedipynb","text":"Basic introduction to StableRLS - Learn the fundamentals of StableRLS - Set up your first environment - Run a basic simulation","title":"\ud83d\udcd3 00-GetStarted.ipynb"},{"location":"notebooks/overview/#01-reward_functionipynb","text":"Understanding and customizing reward functions - Learn how reward functions work - Create custom reward functions - Optimize training performance","title":"\ud83d\udcd3 01-Reward_Function.ipynb"},{"location":"notebooks/overview/#02-advanced_usageipynb","text":"Advanced features and configurations - Explore advanced configuration options - Use advanced simulation features - Integrate with external tools","title":"\ud83d\udcd3 02-Advanced_Usage.ipynb"},{"location":"notebooks/overview/#03-customising_actions_observationsipynb","text":"How to customize the action and observation spaces - Define custom action spaces - Configure observation spaces - Handle complex state representations","title":"\ud83d\udcd3 03-Customising_Actions_Observations.ipynb"},{"location":"notebooks/overview/#04-customising_timingipynb","text":"Timing configuration and control - Configure simulation timing - Handle time-based events - Synchronize with real-time systems","title":"\ud83d\udcd3 04-Customising_Timing.ipynb"},{"location":"notebooks/overview/#running-the-notebooks","text":"To run these notebooks locally: Ensure you have Jupyter installed: pip install jupyter Navigate to the notebooks directory: cd docs/notebooks/ Start Jupyter: jupyter notebook Open any notebook file (.ipynb) in the Jupyter interface","title":"Running the Notebooks"},{"location":"source/API_Reference/","text":"API Reference This section provides detailed API documentation for all StableRLS components, automatically generated from the source code docstrings. Core Components Gym FMU - Main environment class that provides Gymnasium-compatible interface FMU Tools - Core FMU handling class for simulation management Create FMU - Functions for compiling Simulink models into FMU format Config Reader - Configuration file reading and parsing utilities","title":"API Reference"},{"location":"source/API_Reference/#api-reference","text":"This section provides detailed API documentation for all StableRLS components, automatically generated from the source code docstrings.","title":"API Reference"},{"location":"source/API_Reference/#core-components","text":"Gym FMU - Main environment class that provides Gymnasium-compatible interface FMU Tools - Core FMU handling class for simulation management Create FMU - Functions for compiling Simulink models into FMU format Config Reader - Configuration file reading and parsing utilities","title":"Core Components"},{"location":"source/configreader/","text":"Config Reader Class to read configparser files and get specific sections of the config Attributes: config_name : string Path to config that should be read Source code in src/stableRLS/configreader.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 class configreader : \"\"\"Class to read configparser files and get specific sections of the config Attributes: ----------- config_name : string Path to config that should be read \"\"\" def __init__ ( self , config_name ): parser = ConfigParser () parser . optionxform = str # case sensitive found = parser . read ( config_name ) if not found : raise ValueError ( \"No config file found!\" ) self . parser = parser def get_sectionnames ( self ): \"\"\"Returns a list of all available sections Returns ------- sections : list list of available sections \"\"\" return list ( dict ( self . parser ) . keys ()) # get one specified section from config def get ( self , section ): \"\"\"Returns the parameters of one specific section Parameters ------- section : string Specified section for returned parameters Returns ------- sections : list list parameters within the section \"\"\" return smart_parse ( dict ( self . parser . items ( section ))) # get multiple sections from config # TODO this should also work for one config def get_sections ( self , sections ): \"\"\"Returns the parameters of multiple sections Parameters ------- sections : list Specified sections for returned parameters Returns ------- sections : dict dict of sections with their corresponding parameters \"\"\" res = {} for section in sections : res [ section ] = smart_parse ( dict ( self . parser . items ( section ))) return res # return the Ray config section with correct dict # TODO this can be removed def get_ray_agent ( self ): cfg = self . get ( \"Ray\" ) sections = self . getSections () sections . remove ( \"Ray\" ) cfg [ \"env_config\" ] = self . getMulti ( sections ) return cfg get ( section ) Returns the parameters of one specific section Parameters section : string Specified section for returned parameters Returns sections : list list parameters within the section Source code in src/stableRLS/configreader.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def get ( self , section ): \"\"\"Returns the parameters of one specific section Parameters ------- section : string Specified section for returned parameters Returns ------- sections : list list parameters within the section \"\"\" return smart_parse ( dict ( self . parser . items ( section ))) get_sectionnames () Returns a list of all available sections Returns sections : list list of available sections Source code in src/stableRLS/configreader.py 22 23 24 25 26 27 28 29 30 def get_sectionnames ( self ): \"\"\"Returns a list of all available sections Returns ------- sections : list list of available sections \"\"\" return list ( dict ( self . parser ) . keys ()) get_sections ( sections ) Returns the parameters of multiple sections Parameters sections : list Specified sections for returned parameters Returns sections : dict dict of sections with their corresponding parameters Source code in src/stableRLS/configreader.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def get_sections ( self , sections ): \"\"\"Returns the parameters of multiple sections Parameters ------- sections : list Specified sections for returned parameters Returns ------- sections : dict dict of sections with their corresponding parameters \"\"\" res = {} for section in sections : res [ section ] = smart_parse ( dict ( self . parser . items ( section ))) return res","title":"Config Reader"},{"location":"source/configreader/#config-reader","text":"Class to read configparser files and get specific sections of the config","title":"Config Reader"},{"location":"source/configreader/#stableRLS.configreader.configreader--attributes","text":"config_name : string Path to config that should be read Source code in src/stableRLS/configreader.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 class configreader : \"\"\"Class to read configparser files and get specific sections of the config Attributes: ----------- config_name : string Path to config that should be read \"\"\" def __init__ ( self , config_name ): parser = ConfigParser () parser . optionxform = str # case sensitive found = parser . read ( config_name ) if not found : raise ValueError ( \"No config file found!\" ) self . parser = parser def get_sectionnames ( self ): \"\"\"Returns a list of all available sections Returns ------- sections : list list of available sections \"\"\" return list ( dict ( self . parser ) . keys ()) # get one specified section from config def get ( self , section ): \"\"\"Returns the parameters of one specific section Parameters ------- section : string Specified section for returned parameters Returns ------- sections : list list parameters within the section \"\"\" return smart_parse ( dict ( self . parser . items ( section ))) # get multiple sections from config # TODO this should also work for one config def get_sections ( self , sections ): \"\"\"Returns the parameters of multiple sections Parameters ------- sections : list Specified sections for returned parameters Returns ------- sections : dict dict of sections with their corresponding parameters \"\"\" res = {} for section in sections : res [ section ] = smart_parse ( dict ( self . parser . items ( section ))) return res # return the Ray config section with correct dict # TODO this can be removed def get_ray_agent ( self ): cfg = self . get ( \"Ray\" ) sections = self . getSections () sections . remove ( \"Ray\" ) cfg [ \"env_config\" ] = self . getMulti ( sections ) return cfg","title":"Attributes:"},{"location":"source/configreader/#stableRLS.configreader.configreader.get","text":"Returns the parameters of one specific section","title":"get"},{"location":"source/configreader/#stableRLS.configreader.configreader.get--parameters","text":"section : string Specified section for returned parameters","title":"Parameters"},{"location":"source/configreader/#stableRLS.configreader.configreader.get--returns","text":"sections : list list parameters within the section Source code in src/stableRLS/configreader.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def get ( self , section ): \"\"\"Returns the parameters of one specific section Parameters ------- section : string Specified section for returned parameters Returns ------- sections : list list parameters within the section \"\"\" return smart_parse ( dict ( self . parser . items ( section )))","title":"Returns"},{"location":"source/configreader/#stableRLS.configreader.configreader.get_sectionnames","text":"Returns a list of all available sections","title":"get_sectionnames"},{"location":"source/configreader/#stableRLS.configreader.configreader.get_sectionnames--returns","text":"sections : list list of available sections Source code in src/stableRLS/configreader.py 22 23 24 25 26 27 28 29 30 def get_sectionnames ( self ): \"\"\"Returns a list of all available sections Returns ------- sections : list list of available sections \"\"\" return list ( dict ( self . parser ) . keys ())","title":"Returns"},{"location":"source/configreader/#stableRLS.configreader.configreader.get_sections","text":"Returns the parameters of multiple sections","title":"get_sections"},{"location":"source/configreader/#stableRLS.configreader.configreader.get_sections--parameters","text":"sections : list Specified sections for returned parameters","title":"Parameters"},{"location":"source/configreader/#stableRLS.configreader.configreader.get_sections--returns","text":"sections : dict dict of sections with their corresponding parameters Source code in src/stableRLS/configreader.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def get_sections ( self , sections ): \"\"\"Returns the parameters of multiple sections Parameters ------- sections : list Specified sections for returned parameters Returns ------- sections : dict dict of sections with their corresponding parameters \"\"\" res = {} for section in sections : res [ section ] = smart_parse ( dict ( self . parser . items ( section ))) return res","title":"Returns"},{"location":"source/configuration/","text":"Python Configuration The config is supposed to simplify the user's interaction with the package by providing a central place to set all parameters. By default, the config file has to contain three sections: [General] [FMU] [Reinforcement Learning] The parameters within the section will be converted to their respective types and are available within the environment class. Required Parameters The values are examples to show the required type. Name Value Description FMU_path path/to/fmu relative or absolute path to the file stop_time 1 when the time is reached, the simulation ends [s] dt 0.5 fixed timestep of the simulation [s] Optional Parameters Name Value Description action_interval 1.5 every 1.5 seconds the agent can take an action [s] reset_inputs True if this is true the inputs are reset to 0 between each episode start_time 1 specify the start time of the FMU simulation [s] Additional parameters will also be available as self.parameter . Example Config [General] [FMU] FMU_path = 00-Simulink_Linux.fmu stop_time = 1 dt = 0.5 [Reinforcement Learning]","title":"Configuration"},{"location":"source/configuration/#python-configuration","text":"The config is supposed to simplify the user's interaction with the package by providing a central place to set all parameters. By default, the config file has to contain three sections: [General] [FMU] [Reinforcement Learning] The parameters within the section will be converted to their respective types and are available within the environment class.","title":"Python Configuration"},{"location":"source/configuration/#required-parameters","text":"The values are examples to show the required type. Name Value Description FMU_path path/to/fmu relative or absolute path to the file stop_time 1 when the time is reached, the simulation ends [s] dt 0.5 fixed timestep of the simulation [s]","title":"Required Parameters"},{"location":"source/configuration/#optional-parameters","text":"Name Value Description action_interval 1.5 every 1.5 seconds the agent can take an action [s] reset_inputs True if this is true the inputs are reset to 0 between each episode start_time 1 specify the start time of the FMU simulation [s] Additional parameters will also be available as self.parameter .","title":"Optional Parameters"},{"location":"source/configuration/#example-config","text":"[General] [FMU] FMU_path = 00-Simulink_Linux.fmu stop_time = 1 dt = 0.5 [Reinforcement Learning]","title":"Example Config"},{"location":"source/contribute/","text":"Contribution We have a strong background in electrical engineering; therefore, this is the field of research to which we apply this tool. However, we are convinced that there are more subjects for which this tool can be used. In general, this package can be applied to any MATLAB Simulink simulation. If you have any suggestions about improving the package or want to provide additional examples of how you are using this tool, we are happy to work together. Since, Reinforcement Learning has always had many problem specific parts, we decided a fork-and-branch git workflow is the best approach ( Guide ). Creating Issues The issue should briefly point out the issue and contain all relevant information for others to understand the problem or your idea to improve the package. The best case is to include a minimal working example. Please use the following labels to mark your issue: bug , feature , help Development Workflow The guide mentioned above contains all relevant information about the workflow, however, the main steps are summarized below: Fork this repository after you log in Clone the forked repository. The link should contain your username Develop and change the code To contribute your work change the remote repository git remote add upstream https://github.com/rAnnuth/stablerls.git Create a new branch and push your code Check if everything still works as expected by running the Pytests in the ./Test folder Create a pull request where you document your changes","title":"Contributing"},{"location":"source/contribute/#contribution","text":"We have a strong background in electrical engineering; therefore, this is the field of research to which we apply this tool. However, we are convinced that there are more subjects for which this tool can be used. In general, this package can be applied to any MATLAB Simulink simulation. If you have any suggestions about improving the package or want to provide additional examples of how you are using this tool, we are happy to work together. Since, Reinforcement Learning has always had many problem specific parts, we decided a fork-and-branch git workflow is the best approach ( Guide ).","title":"Contribution"},{"location":"source/contribute/#creating-issues","text":"The issue should briefly point out the issue and contain all relevant information for others to understand the problem or your idea to improve the package. The best case is to include a minimal working example. Please use the following labels to mark your issue: bug , feature , help","title":"Creating Issues"},{"location":"source/contribute/#development-workflow","text":"The guide mentioned above contains all relevant information about the workflow, however, the main steps are summarized below: Fork this repository after you log in Clone the forked repository. The link should contain your username Develop and change the code To contribute your work change the remote repository git remote add upstream https://github.com/rAnnuth/stablerls.git Create a new branch and push your code Check if everything still works as expected by running the Pytests in the ./Test folder Create a pull request where you document your changes","title":"Development Workflow"},{"location":"source/createFMU/","text":"Create FMU See https://www.mathworks.com/help/matlab/matlab_external/install-the-matlab-engine-for-python.html for the installation of MATLAB engine. The engine is required to run this function. The function searches for a simulink model defined in the config dict and compiles it into an FMU. The target filename is specified within the config Parameters: cfg : dict Dictionary containing the keys 'FMU_path', 'dt' within the section specified above (default is 'FMU') simulink_model : string path to the Simulink model that should be compiled to a FMU remove_datastore : bool MATLAB has to create a datastore file during compilation. We dont need it afterward and delete it by default. Unless specified otherwise Source code in src/stableRLS/createFMU.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 def createFMU ( cfg , simulink_model , remove_datastore = True ): \"\"\"See https://www.mathworks.com/help/matlab/matlab_external/install-the-matlab-engine-for-python.html for the installation of MATLAB engine. The engine is required to run this function. The function searches for a simulink model defined in the config dict and compiles it into an FMU. The target filename is specified within the config Parameters: ----------- cfg : dict Dictionary containing the keys 'FMU_path', 'dt' within the section specified above (default is 'FMU') simulink_model : string path to the Simulink model that should be compiled to a FMU remove_datastore : bool MATLAB has to create a datastore file during compilation. We dont need it afterward and delete it by default. Unless specified otherwise \"\"\" # get current folder because we need the 'getports.m' function later script_folder = os . path . dirname ( os . path . abspath ( __file__ )) # start matlab engine eng = matlab . engine . start_matlab ( \"-nosplash -noFigureWindows -r\" ) slx_dir = os . path . dirname ( simulink_model ) slx_model = os . path . splitext ( os . path . basename ( simulink_model ))[ 0 ] target_fmu = cfg . get ( section_names )[ \"FMU_path\" ] if not slx_dir == '' : eng . eval ( f \"cd(' { slx_dir } ')\" , nargout = 0 ) eng . eval ( f \"mdl = ' { slx_model } ';\" , nargout = 0 ) eng . eval ( f \"addpath(' { script_folder } ')\" , nargout = 0 ) # dt specifies the step time of the FMU eng . eval ( f \"Ts = { cfg . get ( section_names )[ 'dt' ] } ;\" , nargout = 0 ) # open the system and create bus structure eng . eval ( \"open_system(mdl)\" , nargout = 0 ) eng . eval ( \"set_param(mdl,'DataDictionary','BusSystem.sldd');\" , nargout = 0 ) eng . eval ( \"getports(mdl)\" , nargout = 0 ) # set the solver configuration eng . eval ( \"set_param(mdl,'SolverType','Fixed-step')\" , nargout = 0 ) eng . eval ( \"set_param(mdl,'FixedStep',string(Ts))\" , nargout = 0 ) # start the fmu creation process and quit eng . eval ( \"exportToFMU2CS(mdl, 'CreateModelAfterGeneratingFMU', 'off', 'AddIcon', 'off');\" , nargout = 0 , ) eng . eval ( \"Simulink.data.dictionary.closeAll('-discard')\" , nargout = 0 ) eng . quit () # move FMU to the desired location try : os . rename ( os . path . join ( slx_dir , slx_model ) + '.fmu' , target_fmu ) except FileExistsError : os . remove ( target_fmu ) os . rename ( os . path . join ( slx_dir , slx_model ) + '.fmu' , target_fmu ) # remove MATLAB datastore if remove_datastore : os . remove ( os . path . join ( slx_dir , 'BusSystem.sldd' ))","title":"Create FMU"},{"location":"source/createFMU/#create-fmu","text":"See https://www.mathworks.com/help/matlab/matlab_external/install-the-matlab-engine-for-python.html for the installation of MATLAB engine. The engine is required to run this function. The function searches for a simulink model defined in the config dict and compiles it into an FMU. The target filename is specified within the config","title":"Create FMU"},{"location":"source/createFMU/#stableRLS.createFMU.createFMU--parameters","text":"cfg : dict Dictionary containing the keys 'FMU_path', 'dt' within the section specified above (default is 'FMU') simulink_model : string path to the Simulink model that should be compiled to a FMU remove_datastore : bool MATLAB has to create a datastore file during compilation. We dont need it afterward and delete it by default. Unless specified otherwise Source code in src/stableRLS/createFMU.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 def createFMU ( cfg , simulink_model , remove_datastore = True ): \"\"\"See https://www.mathworks.com/help/matlab/matlab_external/install-the-matlab-engine-for-python.html for the installation of MATLAB engine. The engine is required to run this function. The function searches for a simulink model defined in the config dict and compiles it into an FMU. The target filename is specified within the config Parameters: ----------- cfg : dict Dictionary containing the keys 'FMU_path', 'dt' within the section specified above (default is 'FMU') simulink_model : string path to the Simulink model that should be compiled to a FMU remove_datastore : bool MATLAB has to create a datastore file during compilation. We dont need it afterward and delete it by default. Unless specified otherwise \"\"\" # get current folder because we need the 'getports.m' function later script_folder = os . path . dirname ( os . path . abspath ( __file__ )) # start matlab engine eng = matlab . engine . start_matlab ( \"-nosplash -noFigureWindows -r\" ) slx_dir = os . path . dirname ( simulink_model ) slx_model = os . path . splitext ( os . path . basename ( simulink_model ))[ 0 ] target_fmu = cfg . get ( section_names )[ \"FMU_path\" ] if not slx_dir == '' : eng . eval ( f \"cd(' { slx_dir } ')\" , nargout = 0 ) eng . eval ( f \"mdl = ' { slx_model } ';\" , nargout = 0 ) eng . eval ( f \"addpath(' { script_folder } ')\" , nargout = 0 ) # dt specifies the step time of the FMU eng . eval ( f \"Ts = { cfg . get ( section_names )[ 'dt' ] } ;\" , nargout = 0 ) # open the system and create bus structure eng . eval ( \"open_system(mdl)\" , nargout = 0 ) eng . eval ( \"set_param(mdl,'DataDictionary','BusSystem.sldd');\" , nargout = 0 ) eng . eval ( \"getports(mdl)\" , nargout = 0 ) # set the solver configuration eng . eval ( \"set_param(mdl,'SolverType','Fixed-step')\" , nargout = 0 ) eng . eval ( \"set_param(mdl,'FixedStep',string(Ts))\" , nargout = 0 ) # start the fmu creation process and quit eng . eval ( \"exportToFMU2CS(mdl, 'CreateModelAfterGeneratingFMU', 'off', 'AddIcon', 'off');\" , nargout = 0 , ) eng . eval ( \"Simulink.data.dictionary.closeAll('-discard')\" , nargout = 0 ) eng . quit () # move FMU to the desired location try : os . rename ( os . path . join ( slx_dir , slx_model ) + '.fmu' , target_fmu ) except FileExistsError : os . remove ( target_fmu ) os . rename ( os . path . join ( slx_dir , slx_model ) + '.fmu' , target_fmu ) # remove MATLAB datastore if remove_datastore : os . remove ( os . path . join ( slx_dir , 'BusSystem.sldd' ))","title":"Parameters:"},{"location":"source/fmutools/","text":"FMU Tools This class handels the interaction with the FMU object to separate it from the gymnasium environment. I should not be necessary to modify or interact with this. Attributes config : dict Dictionary containing all config variables. Source code in src/stableRLS/fmutools.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 class FMU : \"\"\" This class handels the interaction with the FMU object to separate it from the gymnasium environment. I should not be necessary to modify or interact with this. Attributes ---------- config : dict Dictionary containing all config variables. \"\"\" def __init__ ( self , config ): \"\"\"Constructor method\"\"\" # make parameters of config file available as class parameters for name in section_names : self . __dict__ . update ( config . get ( name )) # add missing parameters if not hasattr ( self , \"tolerance\" ): self . tolerance = 1e-6 if not hasattr ( self , \"start_time\" ): self . start_time = 0 # this is the default fmpy procedure self . readFMU () logger . debug ( \"Initializing FMU\" ) self . fmu . instantiate () self . initFMU () logger . debug ( \"Reading IOs FMU\" ) self . getIO () # def readFMU ( self ): \"\"\"Unzip and open FMU file\"\"\" logger . debug ( \"Starting to read FMU\" ) logger . info ( \"Using: {} \" . format ( self . FMU_path )) self . description = read_model_description ( self . FMU_path ) self . zipDir = extract ( self . FMU_path ) self . fmu = FMU2Slave ( guid = self . description . guid , unzipDirectory = self . zipDir , modelIdentifier = self . description . coSimulation . modelIdentifier , instanceName = \"instance0\" , ) logger . debug ( \"Success creating FMU object\" ) logger . info ( \"Unzipped in {} \" . format ( self . zipDir )) # initialize FMU def initFMU ( self ): \"\"\"Fmpy requires to setup an experiment before the simulation can be started\"\"\" self . fmu . setupExperiment ( startTime = self . start_time , tolerance = 1e-6 , stopTime = self . stop_time + self . dt ) # set initial inputs self . fmu . enterInitializationMode () self . fmu . exitInitializationMode () # reset FMU to initial state def resetFMU ( self ): \"\"\"Reset the FMU to the inital state\"\"\" logger . debug ( \"Initializing FMU\" ) self . fmu . reset () self . initFMU () # get IO description of FMU def getIO ( self ): \"\"\"Read all available inputs and outputs of the FMU\"\"\" self . output = [ x . variable for x in self . description . outputs ] self . input = [ x for x in self . description . modelVariables if x not in self . output ] # remove time variable since we dont want to set it for i , x in enumerate ( self . input ): if x . name == \"time\" : self . input . pop ( i ) break # put in correct order as GUI self . input = self . input [:: - 1 ] self . output = self . output [:: - 1 ] self . input_names = [ x . name for x in self . input ] self . output_names = [ x . name for x in self . output ] logger . info ( \"Found inputs - access them by the corresponding number:\" ) for i , x in enumerate ( self . input_names ): logger . info ( \" {} : {} \" . format ( i , x )) logger . info ( \"Found outputs - access them by the corresponding number:\" ) for i , x in enumerate ( self . output_names ): logger . info ( \" {} : {} \" . format ( i , x )) def closeFMU ( self ): \"\"\"Terminate FMU after the simulation\"\"\" logger . info ( \"Close fmu and try deleting unzipdir\" ) self . fmu . terminate () self . fmu . freeInstance () shutil . rmtree ( self . zipDir , ignore_errors = True ) # ------------------------------------------------------------------------------------- # getter/setter-functions # ------------------------------------------------------------------------------------- def getInput ( self ): return self . input_names def getNumInput ( self ): return int ( len ( self . input )) def getOutput ( self ): return self . output_names def getNumOutput ( self ): return int ( len ( self . output )) __init__ ( config ) Constructor method Source code in src/stableRLS/fmutools.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def __init__ ( self , config ): \"\"\"Constructor method\"\"\" # make parameters of config file available as class parameters for name in section_names : self . __dict__ . update ( config . get ( name )) # add missing parameters if not hasattr ( self , \"tolerance\" ): self . tolerance = 1e-6 if not hasattr ( self , \"start_time\" ): self . start_time = 0 # this is the default fmpy procedure self . readFMU () logger . debug ( \"Initializing FMU\" ) self . fmu . instantiate () self . initFMU () logger . debug ( \"Reading IOs FMU\" ) self . getIO () closeFMU () Terminate FMU after the simulation Source code in src/stableRLS/fmutools.py 105 106 107 108 109 110 def closeFMU ( self ): \"\"\"Terminate FMU after the simulation\"\"\" logger . info ( \"Close fmu and try deleting unzipdir\" ) self . fmu . terminate () self . fmu . freeInstance () shutil . rmtree ( self . zipDir , ignore_errors = True ) getIO () Read all available inputs and outputs of the FMU Source code in src/stableRLS/fmutools.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 def getIO ( self ): \"\"\"Read all available inputs and outputs of the FMU\"\"\" self . output = [ x . variable for x in self . description . outputs ] self . input = [ x for x in self . description . modelVariables if x not in self . output ] # remove time variable since we dont want to set it for i , x in enumerate ( self . input ): if x . name == \"time\" : self . input . pop ( i ) break # put in correct order as GUI self . input = self . input [:: - 1 ] self . output = self . output [:: - 1 ] self . input_names = [ x . name for x in self . input ] self . output_names = [ x . name for x in self . output ] logger . info ( \"Found inputs - access them by the corresponding number:\" ) for i , x in enumerate ( self . input_names ): logger . info ( \" {} : {} \" . format ( i , x )) logger . info ( \"Found outputs - access them by the corresponding number:\" ) for i , x in enumerate ( self . output_names ): logger . info ( \" {} : {} \" . format ( i , x )) initFMU () Fmpy requires to setup an experiment before the simulation can be started Source code in src/stableRLS/fmutools.py 62 63 64 65 66 67 68 69 def initFMU ( self ): \"\"\"Fmpy requires to setup an experiment before the simulation can be started\"\"\" self . fmu . setupExperiment ( startTime = self . start_time , tolerance = 1e-6 , stopTime = self . stop_time + self . dt ) # set initial inputs self . fmu . enterInitializationMode () self . fmu . exitInitializationMode () readFMU () Unzip and open FMU file Source code in src/stableRLS/fmutools.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def readFMU ( self ): \"\"\"Unzip and open FMU file\"\"\" logger . debug ( \"Starting to read FMU\" ) logger . info ( \"Using: {} \" . format ( self . FMU_path )) self . description = read_model_description ( self . FMU_path ) self . zipDir = extract ( self . FMU_path ) self . fmu = FMU2Slave ( guid = self . description . guid , unzipDirectory = self . zipDir , modelIdentifier = self . description . coSimulation . modelIdentifier , instanceName = \"instance0\" , ) logger . debug ( \"Success creating FMU object\" ) logger . info ( \"Unzipped in {} \" . format ( self . zipDir )) resetFMU () Reset the FMU to the inital state Source code in src/stableRLS/fmutools.py 72 73 74 75 76 def resetFMU ( self ): \"\"\"Reset the FMU to the inital state\"\"\" logger . debug ( \"Initializing FMU\" ) self . fmu . reset () self . initFMU ()","title":"FMU Tools"},{"location":"source/fmutools/#fmu-tools","text":"This class handels the interaction with the FMU object to separate it from the gymnasium environment. I should not be necessary to modify or interact with this.","title":"FMU Tools"},{"location":"source/fmutools/#stableRLS.fmutools.FMU--attributes","text":"config : dict Dictionary containing all config variables. Source code in src/stableRLS/fmutools.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 class FMU : \"\"\" This class handels the interaction with the FMU object to separate it from the gymnasium environment. I should not be necessary to modify or interact with this. Attributes ---------- config : dict Dictionary containing all config variables. \"\"\" def __init__ ( self , config ): \"\"\"Constructor method\"\"\" # make parameters of config file available as class parameters for name in section_names : self . __dict__ . update ( config . get ( name )) # add missing parameters if not hasattr ( self , \"tolerance\" ): self . tolerance = 1e-6 if not hasattr ( self , \"start_time\" ): self . start_time = 0 # this is the default fmpy procedure self . readFMU () logger . debug ( \"Initializing FMU\" ) self . fmu . instantiate () self . initFMU () logger . debug ( \"Reading IOs FMU\" ) self . getIO () # def readFMU ( self ): \"\"\"Unzip and open FMU file\"\"\" logger . debug ( \"Starting to read FMU\" ) logger . info ( \"Using: {} \" . format ( self . FMU_path )) self . description = read_model_description ( self . FMU_path ) self . zipDir = extract ( self . FMU_path ) self . fmu = FMU2Slave ( guid = self . description . guid , unzipDirectory = self . zipDir , modelIdentifier = self . description . coSimulation . modelIdentifier , instanceName = \"instance0\" , ) logger . debug ( \"Success creating FMU object\" ) logger . info ( \"Unzipped in {} \" . format ( self . zipDir )) # initialize FMU def initFMU ( self ): \"\"\"Fmpy requires to setup an experiment before the simulation can be started\"\"\" self . fmu . setupExperiment ( startTime = self . start_time , tolerance = 1e-6 , stopTime = self . stop_time + self . dt ) # set initial inputs self . fmu . enterInitializationMode () self . fmu . exitInitializationMode () # reset FMU to initial state def resetFMU ( self ): \"\"\"Reset the FMU to the inital state\"\"\" logger . debug ( \"Initializing FMU\" ) self . fmu . reset () self . initFMU () # get IO description of FMU def getIO ( self ): \"\"\"Read all available inputs and outputs of the FMU\"\"\" self . output = [ x . variable for x in self . description . outputs ] self . input = [ x for x in self . description . modelVariables if x not in self . output ] # remove time variable since we dont want to set it for i , x in enumerate ( self . input ): if x . name == \"time\" : self . input . pop ( i ) break # put in correct order as GUI self . input = self . input [:: - 1 ] self . output = self . output [:: - 1 ] self . input_names = [ x . name for x in self . input ] self . output_names = [ x . name for x in self . output ] logger . info ( \"Found inputs - access them by the corresponding number:\" ) for i , x in enumerate ( self . input_names ): logger . info ( \" {} : {} \" . format ( i , x )) logger . info ( \"Found outputs - access them by the corresponding number:\" ) for i , x in enumerate ( self . output_names ): logger . info ( \" {} : {} \" . format ( i , x )) def closeFMU ( self ): \"\"\"Terminate FMU after the simulation\"\"\" logger . info ( \"Close fmu and try deleting unzipdir\" ) self . fmu . terminate () self . fmu . freeInstance () shutil . rmtree ( self . zipDir , ignore_errors = True ) # ------------------------------------------------------------------------------------- # getter/setter-functions # ------------------------------------------------------------------------------------- def getInput ( self ): return self . input_names def getNumInput ( self ): return int ( len ( self . input )) def getOutput ( self ): return self . output_names def getNumOutput ( self ): return int ( len ( self . output ))","title":"Attributes"},{"location":"source/fmutools/#stableRLS.fmutools.FMU.__init__","text":"Constructor method Source code in src/stableRLS/fmutools.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def __init__ ( self , config ): \"\"\"Constructor method\"\"\" # make parameters of config file available as class parameters for name in section_names : self . __dict__ . update ( config . get ( name )) # add missing parameters if not hasattr ( self , \"tolerance\" ): self . tolerance = 1e-6 if not hasattr ( self , \"start_time\" ): self . start_time = 0 # this is the default fmpy procedure self . readFMU () logger . debug ( \"Initializing FMU\" ) self . fmu . instantiate () self . initFMU () logger . debug ( \"Reading IOs FMU\" ) self . getIO ()","title":"__init__"},{"location":"source/fmutools/#stableRLS.fmutools.FMU.closeFMU","text":"Terminate FMU after the simulation Source code in src/stableRLS/fmutools.py 105 106 107 108 109 110 def closeFMU ( self ): \"\"\"Terminate FMU after the simulation\"\"\" logger . info ( \"Close fmu and try deleting unzipdir\" ) self . fmu . terminate () self . fmu . freeInstance () shutil . rmtree ( self . zipDir , ignore_errors = True )","title":"closeFMU"},{"location":"source/fmutools/#stableRLS.fmutools.FMU.getIO","text":"Read all available inputs and outputs of the FMU Source code in src/stableRLS/fmutools.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 def getIO ( self ): \"\"\"Read all available inputs and outputs of the FMU\"\"\" self . output = [ x . variable for x in self . description . outputs ] self . input = [ x for x in self . description . modelVariables if x not in self . output ] # remove time variable since we dont want to set it for i , x in enumerate ( self . input ): if x . name == \"time\" : self . input . pop ( i ) break # put in correct order as GUI self . input = self . input [:: - 1 ] self . output = self . output [:: - 1 ] self . input_names = [ x . name for x in self . input ] self . output_names = [ x . name for x in self . output ] logger . info ( \"Found inputs - access them by the corresponding number:\" ) for i , x in enumerate ( self . input_names ): logger . info ( \" {} : {} \" . format ( i , x )) logger . info ( \"Found outputs - access them by the corresponding number:\" ) for i , x in enumerate ( self . output_names ): logger . info ( \" {} : {} \" . format ( i , x ))","title":"getIO"},{"location":"source/fmutools/#stableRLS.fmutools.FMU.initFMU","text":"Fmpy requires to setup an experiment before the simulation can be started Source code in src/stableRLS/fmutools.py 62 63 64 65 66 67 68 69 def initFMU ( self ): \"\"\"Fmpy requires to setup an experiment before the simulation can be started\"\"\" self . fmu . setupExperiment ( startTime = self . start_time , tolerance = 1e-6 , stopTime = self . stop_time + self . dt ) # set initial inputs self . fmu . enterInitializationMode () self . fmu . exitInitializationMode ()","title":"initFMU"},{"location":"source/fmutools/#stableRLS.fmutools.FMU.readFMU","text":"Unzip and open FMU file Source code in src/stableRLS/fmutools.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def readFMU ( self ): \"\"\"Unzip and open FMU file\"\"\" logger . debug ( \"Starting to read FMU\" ) logger . info ( \"Using: {} \" . format ( self . FMU_path )) self . description = read_model_description ( self . FMU_path ) self . zipDir = extract ( self . FMU_path ) self . fmu = FMU2Slave ( guid = self . description . guid , unzipDirectory = self . zipDir , modelIdentifier = self . description . coSimulation . modelIdentifier , instanceName = \"instance0\" , ) logger . debug ( \"Success creating FMU object\" ) logger . info ( \"Unzipped in {} \" . format ( self . zipDir ))","title":"readFMU"},{"location":"source/fmutools/#stableRLS.fmutools.FMU.resetFMU","text":"Reset the FMU to the inital state Source code in src/stableRLS/fmutools.py 72 73 74 75 76 def resetFMU ( self ): \"\"\"Reset the FMU to the inital state\"\"\" logger . debug ( \"Initializing FMU\" ) self . fmu . reset () self . initFMU ()","title":"resetFMU"},{"location":"source/gymFMU/","text":"Gym FMU Bases: Env Custom environment for simulation of FMUs with gymnasium interface. See https://gymnasium.farama.org/ for information about the API and necessary functions. Instantiate this class for the RL agent. Short Guide: Create Simulink FMU using the README guide Create -file-.cfg (config) with all relevant information Create a child class and let the agent do its job! Required: Your custom reward function Optional: Define your own, restricted observation or action spaces Define your own customized observation post-processing Specify additional environment inputs beside the agent's action Export your results Define rollback situations Attributes config : dict Dictionary containing all config variables. Source code in src/stableRLS/gymFMU.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 class StableRLS ( gym . Env ): \"\"\"Custom environment for simulation of FMUs with gymnasium interface. See https://gymnasium.farama.org/ for information about the API and necessary functions. Instantiate this class for the RL agent. Short Guide: 1. Create Simulink FMU using the README guide 2. Create -file-.cfg (config) with all relevant information 3. Create a child class and let the agent do its job! Required: - Your custom reward function Optional: - Define your own, restricted observation or action spaces - Define your own customized observation post-processing - Specify additional environment inputs beside the agent's action - Export your results - Define rollback situations Attributes ---------- config : dict Dictionary containing all config variables. \"\"\" # ---------------------------------------------------------------------------- # Initialization # ---------------------------------------------------------------------------- def __init__ ( self , config ): \"\"\"Constructor method.\"\"\" super ( StableRLS , self ) . __init__ () self . config = config # make parameters of config file available as class parameters for name in section_names : self . __dict__ . update ( config . get ( name )) # set missing parameters to default values # by default, the agent chooses one action per time step if not hasattr ( self , \"action_interval\" ): self . action_interval = self . dt # set start time of the simulation if not hasattr ( self , \"start_time\" ): self . start_time = 0.0 # specify if the inputs are set to zero at each reset() call if not hasattr ( self , \"reset_inputs\" ): self . reset_inputs = True # check config settings for simulation time if not round (( self . stop_time - self . start_time ) / self . dt , 9 ) . is_integer (): self . stop_time = int ( self . stop_time / self . dt ) * self . dt logger . warning ( f \"Incompatible time step and stop time. \\n Using { self . stop_time } as\" \" stop time instead\" ) if not round ( self . action_interval / self . dt , 9 ) . is_integer (): self . action_interval = int ( self . action_interval / self . dt ) * self . dt logger . warning ( \"Incompatible time step and action interval. \\n Using\" f \" { self . action_interval } as interval instead\" ) # calculate number of simulation steps self . steps_between_actions = int ( self . action_interval / self . dt ) self . steps_simulation = int (( self . stop_time - self . start_time ) / self . dt ) + 1 # change action interval to (simulation steps - 1)*dt if it leads to too many steps # between actions if self . steps_simulation < self . steps_between_actions : self . steps_between_actions = self . steps_simulation - 1 self . action_interval = self . steps_between_actions * self . dt logger . warning ( \"Action interval inconsistent with simulation duration. \\n Using\" f \" { self . action_interval } as interval instead\" ) # initialize FMU self . fmu = FMU ( self . config ) self . observation_space = self . set_observation_space () self . action_space = self . set_action_space () # dict for custom vars self . info = {} def set_action_space ( self ): \"\"\"Setter function for the action space of the agent. As default, the action space is defined with respect to the loaded FMU and uses all inputs as actions. For other (restricted) action spaces, this function needs to be modified. For information about possible space definitions, see https://gymnasium.farama.org/api/spaces/. Returns ------- space : gymnasium.space Returns the unbounded action space defined by the FMU inputs \"\"\" high = np . arange ( len ( self . fmu . input )) . astype ( np . float32 ) high [:] = np . inf low = high * - 1 return gym . spaces . Box ( low , high ) def set_observation_space ( self ): \"\"\"Setter function for the observation space of the agent. As default, the action space is defined with respect to the loaded FMU and uses all outputs as observations. For other (restricted) observation spaces, this function needs to be modified. For information about possible space definitions, see https://gymnasium.farama.org/api/spaces/. Returns ------- space : gymnasium.space Returns the unbounded observation space defined by the FMU outputs \"\"\" high = np . arange ( len ( self . fmu . output )) . astype ( np . float32 ) high [:] = np . inf low = high * - 1 return gym . spaces . Box ( low , high ) # ---------------------------------------------------------------------------- # Reset # ---------------------------------------------------------------------------- def reset ( self , seed = None ): \"\"\"Default reset function for gymnasium class. Parameters ---------- seed : int, optional The seed is not used for the FMU since those calculations are deterministic but could be used by the user e.g. for weather models interacting with the FMU during the simulation. Returns ------- observation : gymnasium.space Observation created during reset call (defined behavior by gym) \"\"\" self . seed = seed self . time = self . start_time self . step_count = 0 self . _resetIO () # reset FMU self . FMU_states = {} self . fmu . resetFMU () # calling internal reset function which can be overwritten # and allows customization return self . reset_ ( seed ) def _resetIO ( self ): \"\"\"Resetting lists containing the inputs / outputs and actions of each step and the internal variables.\"\"\" self . inputs = np . empty ([ self . steps_simulation , self . fmu . getNumInput ()]) self . outputs = np . empty ([ self . steps_simulation , self . fmu . getNumOutput ()]) self . times = np . empty ([ self . steps_simulation , 1 ]) self . times [ 0 ] = self . start_time self . step_count = - 1 def reset_ ( self , seed = None ): \"\"\"This internal reset function provides an interface to modify the environment at every reset. You can overwrite this! The code could also depend on the seed and it is possible to modify the returned observation. The default behavior is to simulate the initial step and return all observed values. However, the inputs are not reset therefore. Parameters ---------- seed : int, optional The seed is not used for the FMU since its calculations are deterministic but could be used by the user e.g. for weather models interacting with the FMU during the simulation. \"\"\" if self . reset_inputs : # set all inputs to zero for consistent simulation results for x in self . fmu . input : self . fmu . fmu . setReal ([ x . valueReference ], [ 0 ]) # get the first observation as specified by gymnaisum self . _next_observation ( steps = 1 ) return self . obs_processing ( self . outputs [ self . step_count , :]) # ---------------------------------------------------------------------------- # Step # ---------------------------------------------------------------------------- def step ( self , action ): \"\"\"Run one time step of the environment's dynamics using the agent actions. (Adapted from gymnasium documentation v0.28.1) Parameters ---------- action : list An action provided by the agent to update the environment state. Returns ---------- observation : ObsType An element of the environment's `observation_space` as the next observation due to the agent actions. An example is a numpy array containing the positions and velocities of the pole in CartPole. reward : SupportsFloat The reward as a result of taking the action. terminated : bool Whether the agent reaches the terminal state (as defined under the MDP of the task) which can be positive or negative. An example is reaching the goal state or moving into the lava from the Sutton and Barton, Gridworld. If true, the user needs to call :meth:`reset`. truncated : bool Whether the truncation condition outside the scope of the MDP is satisfied. Typically, this is a timelimit, but could also be used to indicate an agent physically going out of bounds. Can be used to end the episode prematurely before a terminal state is reached. If true, the user needs to call :meth:`reset`. info : dict Contains auxiliary diagnostic information (helpful for debugging, learning, and logging). This might, for instance, contain: metrics that describe the agent's performance state, variables that are hidden from observations, or individual reward terms that are combined to produce the total reward. In OpenAI Gym <v26, it contains \"TimeLimit.truncated\" to distinguish truncation and termination, however this is deprecated in favor of returning terminated and truncated variables. \"\"\" # make sure we have a float32 numpy array action = np . array ( action ) . astype ( np . float32 ) # assign actions to FMU input self . assignAction ( action ) # simulate next step(s) of the FMU self . _next_observation () # get observation vector / outputs of the FMU observation = self . obs_processing ( self . outputs [ self . step_count , :]) # calculate rewards and if needed set truncated flag reward , terminated , truncated , info = self . get_reward ( action , observation ) # end of simulation time reached? if self . time > self . stop_time + 0.5 * self . dt : truncated = True logger . info ( \"Simulation done\" ) return observation , reward , terminated , truncated , info def assignAction ( self , action ): \"\"\"Assign actions to the inputs of the FMU/environment. Parameters ---------- action : list An action provided by the agent to update the environment state. \"\"\" # assign actions to inputs # check if actions are within action space if not self . action_space . contains ( action ): logger . info ( f \"The actions are not within the action space. Action: { action } . Time: { self . time } \" ) # assign actions to the action space for i , val in enumerate ( action ): if val == None : continue self . fmu . fmu . setReal ([ self . fmu . input [ i ] . valueReference ], [ val ]) def _next_observation ( self , steps =- 1 ): \"\"\"It might be required to run the simulation for multiple steps between the inteactions of the agent. By default the agent only observes state after the last of the simulation. Parameters ---------- steps : int, optional Number of steps the FMU model should run \"\"\" # simulate fmu for the specified amount of steps logging . debug ( f \"Starting simulation at simulation time { self . time } [s]\" ) # only during reset the amount of steps is set if steps == - 1 : steps = self . steps_between_actions for _ in np . arange ( steps ): # inputs of the FMU can changed independend of the agent self . FMU_external_input () # simulate FMU for one time step (dt) self . _FMUstep () # save simulation step results self . times [ self . step_count ] = self . time self . inputs [ self . step_count , :] = np . array ( [ self . fmu . fmu . getReal ([ x . valueReference ])[ 0 ] for x in self . fmu . input ] ) self . outputs [ self . step_count , :] = np . array ( [ self . fmu . fmu . getReal ([ x . valueReference ])[ 0 ] for x in self . fmu . output ] ) logging . debug ( \"Simulation for current step done.\" ) def _FMUstep ( self ): \"\"\"This internal step function handles the interaction with the FMU.\"\"\" self . fmu . fmu . doStep ( currentCommunicationPoint = ( self . time ), communicationStepSize = self . dt ) self . step_count += 1 self . time += self . dt def FMU_external_input ( self ): \"\"\"This function is called before each FMU step. Here you can set FMU inputs independent of the agent action. This could be used e.g. for weather data influencing the FMU simulation. Use the code below to access the FMU inputs. self.fmu.fmu.setReal([self.fmu.input[0].valueReference], [value]) \"\"\" pass def obs_processing ( self , observation ): \"\"\"If the agent is supposed to observe modified values the simulated values can be modified here before the reward calculation. Parameters ---------- observation : ObsType The observation by the FMU/ environment Returns ------- observation : ObsType Per default only returns the input but by overwriting the function custom requirements can be met \"\"\" return observation def get_reward ( self , action , observation ): \"\"\"The reward function depends on the specific usecase and must be specified by the user. Parameters ---------- action: ActionType The initial action leads to the observed state of the FMU/ environment observation : ObsType The modified observation by the FMU/ environment (:meth:`obs_processing`) Returns ------- reward : float Calculated reward for the given action and observation terminated : bool Set flag if episode should be terminated. It is automatically terminated if the maximum time is reached truncated : bool Set flag if the agent is truncated info : dict Info dict which is empty by default \"\"\" info = {} reward = 1 terminated = False truncated = False return reward , terminated , truncated , info # ---------------------------------------------------------------------------- # Close / Export / Rollback # ---------------------------------------------------------------------------- def close ( self ): \"\"\"Close FMU and clean up temporary data. This should be called after the simulation ends. \"\"\" self . fmu . closeFMU () def export_results ( self ): \"\"\"This function can be overwritten to acess and export results of the agent.\"\"\" pass def _save_rollbackstate ( self ): \"\"\"Currently matlabs limited export capabilities prevent rollbacks if they enable this at any time this will work. Therefore, the function is currently marked as private. \"\"\" logging . info ( f \"Creating rollback state at time step { self . step_count } \" ) # get the current state state = self . fmu . fmu . getFMUstate () # serialize the state serialized_state = self . fmu . fmu . serializeFMUstate ( state ) self . FMU_states [ str ( self . step_count )] = [ state , serialized_state , self . inputs . copy (), self . outputs . copy (), self . times . copy (), self . step_count , ] def _perform_rollback ( self , step ): \"\"\"Currently matlabs limited export capabilities prevent rollbacks if they enable this at any time this will work. Therefore, the function is currently marked as private. \"\"\" logger . info ( f \"Performing rollback to the state at step { step } \" ) logger . info ( \"If MATLAB created this FMU the rollback did not affect the FMU state\" ) # de-serialize the state deserialized_state = self . fmu . fmu . deSerializeFMUstate ( self . FMU_states [ str ( step )][ 1 ], self . FMU_states [ str ( step )][ 0 ] ) # set the state self . fmu . fmu . setFMUstate ( deserialized_state ) # free memory self . fmu . fmu . freeFMUstate ( deserialized_state ) # self.fmu.fmu.setFMUstate(state=self.FMU_states[str(step)][0]) self . inputs , self . outputs , self . times , self . step_count = self . FMU_states [ str ( step ) ][ 2 :] FMU_external_input () This function is called before each FMU step. Here you can set FMU inputs independent of the agent action. This could be used e.g. for weather data influencing the FMU simulation. Use the code below to access the FMU inputs. self.fmu.fmu.setReal([self.fmu.input[0].valueReference], [value]) Source code in src/stableRLS/gymFMU.py 332 333 334 335 336 337 338 339 340 def FMU_external_input ( self ): \"\"\"This function is called before each FMU step. Here you can set FMU inputs independent of the agent action. This could be used e.g. for weather data influencing the FMU simulation. Use the code below to access the FMU inputs. self.fmu.fmu.setReal([self.fmu.input[0].valueReference], [value]) \"\"\" pass __init__ ( config ) Constructor method. Source code in src/stableRLS/gymFMU.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 def __init__ ( self , config ): \"\"\"Constructor method.\"\"\" super ( StableRLS , self ) . __init__ () self . config = config # make parameters of config file available as class parameters for name in section_names : self . __dict__ . update ( config . get ( name )) # set missing parameters to default values # by default, the agent chooses one action per time step if not hasattr ( self , \"action_interval\" ): self . action_interval = self . dt # set start time of the simulation if not hasattr ( self , \"start_time\" ): self . start_time = 0.0 # specify if the inputs are set to zero at each reset() call if not hasattr ( self , \"reset_inputs\" ): self . reset_inputs = True # check config settings for simulation time if not round (( self . stop_time - self . start_time ) / self . dt , 9 ) . is_integer (): self . stop_time = int ( self . stop_time / self . dt ) * self . dt logger . warning ( f \"Incompatible time step and stop time. \\n Using { self . stop_time } as\" \" stop time instead\" ) if not round ( self . action_interval / self . dt , 9 ) . is_integer (): self . action_interval = int ( self . action_interval / self . dt ) * self . dt logger . warning ( \"Incompatible time step and action interval. \\n Using\" f \" { self . action_interval } as interval instead\" ) # calculate number of simulation steps self . steps_between_actions = int ( self . action_interval / self . dt ) self . steps_simulation = int (( self . stop_time - self . start_time ) / self . dt ) + 1 # change action interval to (simulation steps - 1)*dt if it leads to too many steps # between actions if self . steps_simulation < self . steps_between_actions : self . steps_between_actions = self . steps_simulation - 1 self . action_interval = self . steps_between_actions * self . dt logger . warning ( \"Action interval inconsistent with simulation duration. \\n Using\" f \" { self . action_interval } as interval instead\" ) # initialize FMU self . fmu = FMU ( self . config ) self . observation_space = self . set_observation_space () self . action_space = self . set_action_space () # dict for custom vars self . info = {} assignAction ( action ) Assign actions to the inputs of the FMU/environment. Parameters action : list An action provided by the agent to update the environment state. Source code in src/stableRLS/gymFMU.py 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 def assignAction ( self , action ): \"\"\"Assign actions to the inputs of the FMU/environment. Parameters ---------- action : list An action provided by the agent to update the environment state. \"\"\" # assign actions to inputs # check if actions are within action space if not self . action_space . contains ( action ): logger . info ( f \"The actions are not within the action space. Action: { action } . Time: { self . time } \" ) # assign actions to the action space for i , val in enumerate ( action ): if val == None : continue self . fmu . fmu . setReal ([ self . fmu . input [ i ] . valueReference ], [ val ]) close () Close FMU and clean up temporary data. This should be called after the simulation ends. Source code in src/stableRLS/gymFMU.py 391 392 393 394 395 396 def close ( self ): \"\"\"Close FMU and clean up temporary data. This should be called after the simulation ends. \"\"\" self . fmu . closeFMU () export_results () This function can be overwritten to acess and export results of the agent. Source code in src/stableRLS/gymFMU.py 398 399 400 401 def export_results ( self ): \"\"\"This function can be overwritten to acess and export results of the agent.\"\"\" pass get_reward ( action , observation ) The reward function depends on the specific usecase and must be specified by the user. Parameters action: ActionType The initial action leads to the observed state of the FMU/ environment observation : ObsType The modified observation by the FMU/ environment (:meth: obs_processing ) Returns reward : float Calculated reward for the given action and observation terminated : bool Set flag if episode should be terminated. It is automatically terminated if the maximum time is reached truncated : bool Set flag if the agent is truncated info : dict Info dict which is empty by default Source code in src/stableRLS/gymFMU.py 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 def get_reward ( self , action , observation ): \"\"\"The reward function depends on the specific usecase and must be specified by the user. Parameters ---------- action: ActionType The initial action leads to the observed state of the FMU/ environment observation : ObsType The modified observation by the FMU/ environment (:meth:`obs_processing`) Returns ------- reward : float Calculated reward for the given action and observation terminated : bool Set flag if episode should be terminated. It is automatically terminated if the maximum time is reached truncated : bool Set flag if the agent is truncated info : dict Info dict which is empty by default \"\"\" info = {} reward = 1 terminated = False truncated = False return reward , terminated , truncated , info obs_processing ( observation ) If the agent is supposed to observe modified values the simulated values can be modified here before the reward calculation. Parameters observation : ObsType The observation by the FMU/ environment Returns observation : ObsType Per default only returns the input but by overwriting the function custom requirements can be met Source code in src/stableRLS/gymFMU.py 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 def obs_processing ( self , observation ): \"\"\"If the agent is supposed to observe modified values the simulated values can be modified here before the reward calculation. Parameters ---------- observation : ObsType The observation by the FMU/ environment Returns ------- observation : ObsType Per default only returns the input but by overwriting the function custom requirements can be met \"\"\" return observation reset ( seed = None ) Default reset function for gymnasium class. Parameters seed : int, optional The seed is not used for the FMU since those calculations are deterministic but could be used by the user e.g. for weather models interacting with the FMU during the simulation. Returns observation : gymnasium.space Observation created during reset call (defined behavior by gym) Source code in src/stableRLS/gymFMU.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 def reset ( self , seed = None ): \"\"\"Default reset function for gymnasium class. Parameters ---------- seed : int, optional The seed is not used for the FMU since those calculations are deterministic but could be used by the user e.g. for weather models interacting with the FMU during the simulation. Returns ------- observation : gymnasium.space Observation created during reset call (defined behavior by gym) \"\"\" self . seed = seed self . time = self . start_time self . step_count = 0 self . _resetIO () # reset FMU self . FMU_states = {} self . fmu . resetFMU () # calling internal reset function which can be overwritten # and allows customization return self . reset_ ( seed ) reset_ ( seed = None ) This internal reset function provides an interface to modify the environment at every reset. You can overwrite this! The code could also depend on the seed and it is possible to modify the returned observation. The default behavior is to simulate the initial step and return all observed values. However, the inputs are not reset therefore. Parameters seed : int, optional The seed is not used for the FMU since its calculations are deterministic but could be used by the user e.g. for weather models interacting with the FMU during the simulation. Source code in src/stableRLS/gymFMU.py 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def reset_ ( self , seed = None ): \"\"\"This internal reset function provides an interface to modify the environment at every reset. You can overwrite this! The code could also depend on the seed and it is possible to modify the returned observation. The default behavior is to simulate the initial step and return all observed values. However, the inputs are not reset therefore. Parameters ---------- seed : int, optional The seed is not used for the FMU since its calculations are deterministic but could be used by the user e.g. for weather models interacting with the FMU during the simulation. \"\"\" if self . reset_inputs : # set all inputs to zero for consistent simulation results for x in self . fmu . input : self . fmu . fmu . setReal ([ x . valueReference ], [ 0 ]) # get the first observation as specified by gymnaisum self . _next_observation ( steps = 1 ) return self . obs_processing ( self . outputs [ self . step_count , :]) set_action_space () Setter function for the action space of the agent. As default, the action space is defined with respect to the loaded FMU and uses all inputs as actions. For other (restricted) action spaces, this function needs to be modified. For information about possible space definitions, see https://gymnasium.farama.org/api/spaces/. Returns space : gymnasium.space Returns the unbounded action space defined by the FMU inputs Source code in src/stableRLS/gymFMU.py 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 def set_action_space ( self ): \"\"\"Setter function for the action space of the agent. As default, the action space is defined with respect to the loaded FMU and uses all inputs as actions. For other (restricted) action spaces, this function needs to be modified. For information about possible space definitions, see https://gymnasium.farama.org/api/spaces/. Returns ------- space : gymnasium.space Returns the unbounded action space defined by the FMU inputs \"\"\" high = np . arange ( len ( self . fmu . input )) . astype ( np . float32 ) high [:] = np . inf low = high * - 1 return gym . spaces . Box ( low , high ) set_observation_space () Setter function for the observation space of the agent. As default, the action space is defined with respect to the loaded FMU and uses all outputs as observations. For other (restricted) observation spaces, this function needs to be modified. For information about possible space definitions, see https://gymnasium.farama.org/api/spaces/. Returns space : gymnasium.space Returns the unbounded observation space defined by the FMU outputs Source code in src/stableRLS/gymFMU.py 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 def set_observation_space ( self ): \"\"\"Setter function for the observation space of the agent. As default, the action space is defined with respect to the loaded FMU and uses all outputs as observations. For other (restricted) observation spaces, this function needs to be modified. For information about possible space definitions, see https://gymnasium.farama.org/api/spaces/. Returns ------- space : gymnasium.space Returns the unbounded observation space defined by the FMU outputs \"\"\" high = np . arange ( len ( self . fmu . output )) . astype ( np . float32 ) high [:] = np . inf low = high * - 1 return gym . spaces . Box ( low , high ) step ( action ) Run one time step of the environment's dynamics using the agent actions. (Adapted from gymnasium documentation v0.28.1) Parameters action : list An action provided by the agent to update the environment state. Returns observation : ObsType An element of the environment's observation_space as the next observation due to the agent actions. An example is a numpy array containing the positions and velocities of the pole in CartPole. reward : SupportsFloat The reward as a result of taking the action. terminated : bool Whether the agent reaches the terminal state (as defined under the MDP of the task) which can be positive or negative. An example is reaching the goal state or moving into the lava from the Sutton and Barton, Gridworld. If true, the user needs to call :meth: reset . truncated : bool Whether the truncation condition outside the scope of the MDP is satisfied. Typically, this is a timelimit, but could also be used to indicate an agent physically going out of bounds. Can be used to end the episode prematurely before a terminal state is reached. If true, the user needs to call :meth: reset . info : dict Contains auxiliary diagnostic information (helpful for debugging, learning, and logging). This might, for instance, contain: metrics that describe the agent's performance state, variables that are hidden from observations, or individual reward terms that are combined to produce the total reward. In OpenAI Gym <v26, it contains \"TimeLimit.truncated\" to distinguish truncation and termination, however this is deprecated in favor of returning terminated and truncated variables. Source code in src/stableRLS/gymFMU.py 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 def step ( self , action ): \"\"\"Run one time step of the environment's dynamics using the agent actions. (Adapted from gymnasium documentation v0.28.1) Parameters ---------- action : list An action provided by the agent to update the environment state. Returns ---------- observation : ObsType An element of the environment's `observation_space` as the next observation due to the agent actions. An example is a numpy array containing the positions and velocities of the pole in CartPole. reward : SupportsFloat The reward as a result of taking the action. terminated : bool Whether the agent reaches the terminal state (as defined under the MDP of the task) which can be positive or negative. An example is reaching the goal state or moving into the lava from the Sutton and Barton, Gridworld. If true, the user needs to call :meth:`reset`. truncated : bool Whether the truncation condition outside the scope of the MDP is satisfied. Typically, this is a timelimit, but could also be used to indicate an agent physically going out of bounds. Can be used to end the episode prematurely before a terminal state is reached. If true, the user needs to call :meth:`reset`. info : dict Contains auxiliary diagnostic information (helpful for debugging, learning, and logging). This might, for instance, contain: metrics that describe the agent's performance state, variables that are hidden from observations, or individual reward terms that are combined to produce the total reward. In OpenAI Gym <v26, it contains \"TimeLimit.truncated\" to distinguish truncation and termination, however this is deprecated in favor of returning terminated and truncated variables. \"\"\" # make sure we have a float32 numpy array action = np . array ( action ) . astype ( np . float32 ) # assign actions to FMU input self . assignAction ( action ) # simulate next step(s) of the FMU self . _next_observation () # get observation vector / outputs of the FMU observation = self . obs_processing ( self . outputs [ self . step_count , :]) # calculate rewards and if needed set truncated flag reward , terminated , truncated , info = self . get_reward ( action , observation ) # end of simulation time reached? if self . time > self . stop_time + 0.5 * self . dt : truncated = True logger . info ( \"Simulation done\" ) return observation , reward , terminated , truncated , info","title":"Gym FMU"},{"location":"source/gymFMU/#gym-fmu","text":"Bases: Env Custom environment for simulation of FMUs with gymnasium interface. See https://gymnasium.farama.org/ for information about the API and necessary functions. Instantiate this class for the RL agent. Short Guide: Create Simulink FMU using the README guide Create -file-.cfg (config) with all relevant information Create a child class and let the agent do its job! Required: Your custom reward function Optional: Define your own, restricted observation or action spaces Define your own customized observation post-processing Specify additional environment inputs beside the agent's action Export your results Define rollback situations","title":"Gym FMU"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS--attributes","text":"config : dict Dictionary containing all config variables. Source code in src/stableRLS/gymFMU.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 class StableRLS ( gym . Env ): \"\"\"Custom environment for simulation of FMUs with gymnasium interface. See https://gymnasium.farama.org/ for information about the API and necessary functions. Instantiate this class for the RL agent. Short Guide: 1. Create Simulink FMU using the README guide 2. Create -file-.cfg (config) with all relevant information 3. Create a child class and let the agent do its job! Required: - Your custom reward function Optional: - Define your own, restricted observation or action spaces - Define your own customized observation post-processing - Specify additional environment inputs beside the agent's action - Export your results - Define rollback situations Attributes ---------- config : dict Dictionary containing all config variables. \"\"\" # ---------------------------------------------------------------------------- # Initialization # ---------------------------------------------------------------------------- def __init__ ( self , config ): \"\"\"Constructor method.\"\"\" super ( StableRLS , self ) . __init__ () self . config = config # make parameters of config file available as class parameters for name in section_names : self . __dict__ . update ( config . get ( name )) # set missing parameters to default values # by default, the agent chooses one action per time step if not hasattr ( self , \"action_interval\" ): self . action_interval = self . dt # set start time of the simulation if not hasattr ( self , \"start_time\" ): self . start_time = 0.0 # specify if the inputs are set to zero at each reset() call if not hasattr ( self , \"reset_inputs\" ): self . reset_inputs = True # check config settings for simulation time if not round (( self . stop_time - self . start_time ) / self . dt , 9 ) . is_integer (): self . stop_time = int ( self . stop_time / self . dt ) * self . dt logger . warning ( f \"Incompatible time step and stop time. \\n Using { self . stop_time } as\" \" stop time instead\" ) if not round ( self . action_interval / self . dt , 9 ) . is_integer (): self . action_interval = int ( self . action_interval / self . dt ) * self . dt logger . warning ( \"Incompatible time step and action interval. \\n Using\" f \" { self . action_interval } as interval instead\" ) # calculate number of simulation steps self . steps_between_actions = int ( self . action_interval / self . dt ) self . steps_simulation = int (( self . stop_time - self . start_time ) / self . dt ) + 1 # change action interval to (simulation steps - 1)*dt if it leads to too many steps # between actions if self . steps_simulation < self . steps_between_actions : self . steps_between_actions = self . steps_simulation - 1 self . action_interval = self . steps_between_actions * self . dt logger . warning ( \"Action interval inconsistent with simulation duration. \\n Using\" f \" { self . action_interval } as interval instead\" ) # initialize FMU self . fmu = FMU ( self . config ) self . observation_space = self . set_observation_space () self . action_space = self . set_action_space () # dict for custom vars self . info = {} def set_action_space ( self ): \"\"\"Setter function for the action space of the agent. As default, the action space is defined with respect to the loaded FMU and uses all inputs as actions. For other (restricted) action spaces, this function needs to be modified. For information about possible space definitions, see https://gymnasium.farama.org/api/spaces/. Returns ------- space : gymnasium.space Returns the unbounded action space defined by the FMU inputs \"\"\" high = np . arange ( len ( self . fmu . input )) . astype ( np . float32 ) high [:] = np . inf low = high * - 1 return gym . spaces . Box ( low , high ) def set_observation_space ( self ): \"\"\"Setter function for the observation space of the agent. As default, the action space is defined with respect to the loaded FMU and uses all outputs as observations. For other (restricted) observation spaces, this function needs to be modified. For information about possible space definitions, see https://gymnasium.farama.org/api/spaces/. Returns ------- space : gymnasium.space Returns the unbounded observation space defined by the FMU outputs \"\"\" high = np . arange ( len ( self . fmu . output )) . astype ( np . float32 ) high [:] = np . inf low = high * - 1 return gym . spaces . Box ( low , high ) # ---------------------------------------------------------------------------- # Reset # ---------------------------------------------------------------------------- def reset ( self , seed = None ): \"\"\"Default reset function for gymnasium class. Parameters ---------- seed : int, optional The seed is not used for the FMU since those calculations are deterministic but could be used by the user e.g. for weather models interacting with the FMU during the simulation. Returns ------- observation : gymnasium.space Observation created during reset call (defined behavior by gym) \"\"\" self . seed = seed self . time = self . start_time self . step_count = 0 self . _resetIO () # reset FMU self . FMU_states = {} self . fmu . resetFMU () # calling internal reset function which can be overwritten # and allows customization return self . reset_ ( seed ) def _resetIO ( self ): \"\"\"Resetting lists containing the inputs / outputs and actions of each step and the internal variables.\"\"\" self . inputs = np . empty ([ self . steps_simulation , self . fmu . getNumInput ()]) self . outputs = np . empty ([ self . steps_simulation , self . fmu . getNumOutput ()]) self . times = np . empty ([ self . steps_simulation , 1 ]) self . times [ 0 ] = self . start_time self . step_count = - 1 def reset_ ( self , seed = None ): \"\"\"This internal reset function provides an interface to modify the environment at every reset. You can overwrite this! The code could also depend on the seed and it is possible to modify the returned observation. The default behavior is to simulate the initial step and return all observed values. However, the inputs are not reset therefore. Parameters ---------- seed : int, optional The seed is not used for the FMU since its calculations are deterministic but could be used by the user e.g. for weather models interacting with the FMU during the simulation. \"\"\" if self . reset_inputs : # set all inputs to zero for consistent simulation results for x in self . fmu . input : self . fmu . fmu . setReal ([ x . valueReference ], [ 0 ]) # get the first observation as specified by gymnaisum self . _next_observation ( steps = 1 ) return self . obs_processing ( self . outputs [ self . step_count , :]) # ---------------------------------------------------------------------------- # Step # ---------------------------------------------------------------------------- def step ( self , action ): \"\"\"Run one time step of the environment's dynamics using the agent actions. (Adapted from gymnasium documentation v0.28.1) Parameters ---------- action : list An action provided by the agent to update the environment state. Returns ---------- observation : ObsType An element of the environment's `observation_space` as the next observation due to the agent actions. An example is a numpy array containing the positions and velocities of the pole in CartPole. reward : SupportsFloat The reward as a result of taking the action. terminated : bool Whether the agent reaches the terminal state (as defined under the MDP of the task) which can be positive or negative. An example is reaching the goal state or moving into the lava from the Sutton and Barton, Gridworld. If true, the user needs to call :meth:`reset`. truncated : bool Whether the truncation condition outside the scope of the MDP is satisfied. Typically, this is a timelimit, but could also be used to indicate an agent physically going out of bounds. Can be used to end the episode prematurely before a terminal state is reached. If true, the user needs to call :meth:`reset`. info : dict Contains auxiliary diagnostic information (helpful for debugging, learning, and logging). This might, for instance, contain: metrics that describe the agent's performance state, variables that are hidden from observations, or individual reward terms that are combined to produce the total reward. In OpenAI Gym <v26, it contains \"TimeLimit.truncated\" to distinguish truncation and termination, however this is deprecated in favor of returning terminated and truncated variables. \"\"\" # make sure we have a float32 numpy array action = np . array ( action ) . astype ( np . float32 ) # assign actions to FMU input self . assignAction ( action ) # simulate next step(s) of the FMU self . _next_observation () # get observation vector / outputs of the FMU observation = self . obs_processing ( self . outputs [ self . step_count , :]) # calculate rewards and if needed set truncated flag reward , terminated , truncated , info = self . get_reward ( action , observation ) # end of simulation time reached? if self . time > self . stop_time + 0.5 * self . dt : truncated = True logger . info ( \"Simulation done\" ) return observation , reward , terminated , truncated , info def assignAction ( self , action ): \"\"\"Assign actions to the inputs of the FMU/environment. Parameters ---------- action : list An action provided by the agent to update the environment state. \"\"\" # assign actions to inputs # check if actions are within action space if not self . action_space . contains ( action ): logger . info ( f \"The actions are not within the action space. Action: { action } . Time: { self . time } \" ) # assign actions to the action space for i , val in enumerate ( action ): if val == None : continue self . fmu . fmu . setReal ([ self . fmu . input [ i ] . valueReference ], [ val ]) def _next_observation ( self , steps =- 1 ): \"\"\"It might be required to run the simulation for multiple steps between the inteactions of the agent. By default the agent only observes state after the last of the simulation. Parameters ---------- steps : int, optional Number of steps the FMU model should run \"\"\" # simulate fmu for the specified amount of steps logging . debug ( f \"Starting simulation at simulation time { self . time } [s]\" ) # only during reset the amount of steps is set if steps == - 1 : steps = self . steps_between_actions for _ in np . arange ( steps ): # inputs of the FMU can changed independend of the agent self . FMU_external_input () # simulate FMU for one time step (dt) self . _FMUstep () # save simulation step results self . times [ self . step_count ] = self . time self . inputs [ self . step_count , :] = np . array ( [ self . fmu . fmu . getReal ([ x . valueReference ])[ 0 ] for x in self . fmu . input ] ) self . outputs [ self . step_count , :] = np . array ( [ self . fmu . fmu . getReal ([ x . valueReference ])[ 0 ] for x in self . fmu . output ] ) logging . debug ( \"Simulation for current step done.\" ) def _FMUstep ( self ): \"\"\"This internal step function handles the interaction with the FMU.\"\"\" self . fmu . fmu . doStep ( currentCommunicationPoint = ( self . time ), communicationStepSize = self . dt ) self . step_count += 1 self . time += self . dt def FMU_external_input ( self ): \"\"\"This function is called before each FMU step. Here you can set FMU inputs independent of the agent action. This could be used e.g. for weather data influencing the FMU simulation. Use the code below to access the FMU inputs. self.fmu.fmu.setReal([self.fmu.input[0].valueReference], [value]) \"\"\" pass def obs_processing ( self , observation ): \"\"\"If the agent is supposed to observe modified values the simulated values can be modified here before the reward calculation. Parameters ---------- observation : ObsType The observation by the FMU/ environment Returns ------- observation : ObsType Per default only returns the input but by overwriting the function custom requirements can be met \"\"\" return observation def get_reward ( self , action , observation ): \"\"\"The reward function depends on the specific usecase and must be specified by the user. Parameters ---------- action: ActionType The initial action leads to the observed state of the FMU/ environment observation : ObsType The modified observation by the FMU/ environment (:meth:`obs_processing`) Returns ------- reward : float Calculated reward for the given action and observation terminated : bool Set flag if episode should be terminated. It is automatically terminated if the maximum time is reached truncated : bool Set flag if the agent is truncated info : dict Info dict which is empty by default \"\"\" info = {} reward = 1 terminated = False truncated = False return reward , terminated , truncated , info # ---------------------------------------------------------------------------- # Close / Export / Rollback # ---------------------------------------------------------------------------- def close ( self ): \"\"\"Close FMU and clean up temporary data. This should be called after the simulation ends. \"\"\" self . fmu . closeFMU () def export_results ( self ): \"\"\"This function can be overwritten to acess and export results of the agent.\"\"\" pass def _save_rollbackstate ( self ): \"\"\"Currently matlabs limited export capabilities prevent rollbacks if they enable this at any time this will work. Therefore, the function is currently marked as private. \"\"\" logging . info ( f \"Creating rollback state at time step { self . step_count } \" ) # get the current state state = self . fmu . fmu . getFMUstate () # serialize the state serialized_state = self . fmu . fmu . serializeFMUstate ( state ) self . FMU_states [ str ( self . step_count )] = [ state , serialized_state , self . inputs . copy (), self . outputs . copy (), self . times . copy (), self . step_count , ] def _perform_rollback ( self , step ): \"\"\"Currently matlabs limited export capabilities prevent rollbacks if they enable this at any time this will work. Therefore, the function is currently marked as private. \"\"\" logger . info ( f \"Performing rollback to the state at step { step } \" ) logger . info ( \"If MATLAB created this FMU the rollback did not affect the FMU state\" ) # de-serialize the state deserialized_state = self . fmu . fmu . deSerializeFMUstate ( self . FMU_states [ str ( step )][ 1 ], self . FMU_states [ str ( step )][ 0 ] ) # set the state self . fmu . fmu . setFMUstate ( deserialized_state ) # free memory self . fmu . fmu . freeFMUstate ( deserialized_state ) # self.fmu.fmu.setFMUstate(state=self.FMU_states[str(step)][0]) self . inputs , self . outputs , self . times , self . step_count = self . FMU_states [ str ( step ) ][ 2 :]","title":"Attributes"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.FMU_external_input","text":"This function is called before each FMU step. Here you can set FMU inputs independent of the agent action. This could be used e.g. for weather data influencing the FMU simulation. Use the code below to access the FMU inputs. self.fmu.fmu.setReal([self.fmu.input[0].valueReference], [value]) Source code in src/stableRLS/gymFMU.py 332 333 334 335 336 337 338 339 340 def FMU_external_input ( self ): \"\"\"This function is called before each FMU step. Here you can set FMU inputs independent of the agent action. This could be used e.g. for weather data influencing the FMU simulation. Use the code below to access the FMU inputs. self.fmu.fmu.setReal([self.fmu.input[0].valueReference], [value]) \"\"\" pass","title":"FMU_external_input"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.__init__","text":"Constructor method. Source code in src/stableRLS/gymFMU.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 def __init__ ( self , config ): \"\"\"Constructor method.\"\"\" super ( StableRLS , self ) . __init__ () self . config = config # make parameters of config file available as class parameters for name in section_names : self . __dict__ . update ( config . get ( name )) # set missing parameters to default values # by default, the agent chooses one action per time step if not hasattr ( self , \"action_interval\" ): self . action_interval = self . dt # set start time of the simulation if not hasattr ( self , \"start_time\" ): self . start_time = 0.0 # specify if the inputs are set to zero at each reset() call if not hasattr ( self , \"reset_inputs\" ): self . reset_inputs = True # check config settings for simulation time if not round (( self . stop_time - self . start_time ) / self . dt , 9 ) . is_integer (): self . stop_time = int ( self . stop_time / self . dt ) * self . dt logger . warning ( f \"Incompatible time step and stop time. \\n Using { self . stop_time } as\" \" stop time instead\" ) if not round ( self . action_interval / self . dt , 9 ) . is_integer (): self . action_interval = int ( self . action_interval / self . dt ) * self . dt logger . warning ( \"Incompatible time step and action interval. \\n Using\" f \" { self . action_interval } as interval instead\" ) # calculate number of simulation steps self . steps_between_actions = int ( self . action_interval / self . dt ) self . steps_simulation = int (( self . stop_time - self . start_time ) / self . dt ) + 1 # change action interval to (simulation steps - 1)*dt if it leads to too many steps # between actions if self . steps_simulation < self . steps_between_actions : self . steps_between_actions = self . steps_simulation - 1 self . action_interval = self . steps_between_actions * self . dt logger . warning ( \"Action interval inconsistent with simulation duration. \\n Using\" f \" { self . action_interval } as interval instead\" ) # initialize FMU self . fmu = FMU ( self . config ) self . observation_space = self . set_observation_space () self . action_space = self . set_action_space () # dict for custom vars self . info = {}","title":"__init__"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.assignAction","text":"Assign actions to the inputs of the FMU/environment.","title":"assignAction"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.assignAction--parameters","text":"action : list An action provided by the agent to update the environment state. Source code in src/stableRLS/gymFMU.py 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 def assignAction ( self , action ): \"\"\"Assign actions to the inputs of the FMU/environment. Parameters ---------- action : list An action provided by the agent to update the environment state. \"\"\" # assign actions to inputs # check if actions are within action space if not self . action_space . contains ( action ): logger . info ( f \"The actions are not within the action space. Action: { action } . Time: { self . time } \" ) # assign actions to the action space for i , val in enumerate ( action ): if val == None : continue self . fmu . fmu . setReal ([ self . fmu . input [ i ] . valueReference ], [ val ])","title":"Parameters"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.close","text":"Close FMU and clean up temporary data. This should be called after the simulation ends. Source code in src/stableRLS/gymFMU.py 391 392 393 394 395 396 def close ( self ): \"\"\"Close FMU and clean up temporary data. This should be called after the simulation ends. \"\"\" self . fmu . closeFMU ()","title":"close"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.export_results","text":"This function can be overwritten to acess and export results of the agent. Source code in src/stableRLS/gymFMU.py 398 399 400 401 def export_results ( self ): \"\"\"This function can be overwritten to acess and export results of the agent.\"\"\" pass","title":"export_results"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.get_reward","text":"The reward function depends on the specific usecase and must be specified by the user.","title":"get_reward"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.get_reward--parameters","text":"action: ActionType The initial action leads to the observed state of the FMU/ environment observation : ObsType The modified observation by the FMU/ environment (:meth: obs_processing )","title":"Parameters"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.get_reward--returns","text":"reward : float Calculated reward for the given action and observation terminated : bool Set flag if episode should be terminated. It is automatically terminated if the maximum time is reached truncated : bool Set flag if the agent is truncated info : dict Info dict which is empty by default Source code in src/stableRLS/gymFMU.py 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 def get_reward ( self , action , observation ): \"\"\"The reward function depends on the specific usecase and must be specified by the user. Parameters ---------- action: ActionType The initial action leads to the observed state of the FMU/ environment observation : ObsType The modified observation by the FMU/ environment (:meth:`obs_processing`) Returns ------- reward : float Calculated reward for the given action and observation terminated : bool Set flag if episode should be terminated. It is automatically terminated if the maximum time is reached truncated : bool Set flag if the agent is truncated info : dict Info dict which is empty by default \"\"\" info = {} reward = 1 terminated = False truncated = False return reward , terminated , truncated , info","title":"Returns"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.obs_processing","text":"If the agent is supposed to observe modified values the simulated values can be modified here before the reward calculation.","title":"obs_processing"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.obs_processing--parameters","text":"observation : ObsType The observation by the FMU/ environment","title":"Parameters"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.obs_processing--returns","text":"observation : ObsType Per default only returns the input but by overwriting the function custom requirements can be met Source code in src/stableRLS/gymFMU.py 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 def obs_processing ( self , observation ): \"\"\"If the agent is supposed to observe modified values the simulated values can be modified here before the reward calculation. Parameters ---------- observation : ObsType The observation by the FMU/ environment Returns ------- observation : ObsType Per default only returns the input but by overwriting the function custom requirements can be met \"\"\" return observation","title":"Returns"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.reset","text":"Default reset function for gymnasium class.","title":"reset"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.reset--parameters","text":"seed : int, optional The seed is not used for the FMU since those calculations are deterministic but could be used by the user e.g. for weather models interacting with the FMU during the simulation.","title":"Parameters"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.reset--returns","text":"observation : gymnasium.space Observation created during reset call (defined behavior by gym) Source code in src/stableRLS/gymFMU.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 def reset ( self , seed = None ): \"\"\"Default reset function for gymnasium class. Parameters ---------- seed : int, optional The seed is not used for the FMU since those calculations are deterministic but could be used by the user e.g. for weather models interacting with the FMU during the simulation. Returns ------- observation : gymnasium.space Observation created during reset call (defined behavior by gym) \"\"\" self . seed = seed self . time = self . start_time self . step_count = 0 self . _resetIO () # reset FMU self . FMU_states = {} self . fmu . resetFMU () # calling internal reset function which can be overwritten # and allows customization return self . reset_ ( seed )","title":"Returns"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.reset_","text":"This internal reset function provides an interface to modify the environment at every reset. You can overwrite this! The code could also depend on the seed and it is possible to modify the returned observation. The default behavior is to simulate the initial step and return all observed values. However, the inputs are not reset therefore.","title":"reset_"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.reset_--parameters","text":"seed : int, optional The seed is not used for the FMU since its calculations are deterministic but could be used by the user e.g. for weather models interacting with the FMU during the simulation. Source code in src/stableRLS/gymFMU.py 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def reset_ ( self , seed = None ): \"\"\"This internal reset function provides an interface to modify the environment at every reset. You can overwrite this! The code could also depend on the seed and it is possible to modify the returned observation. The default behavior is to simulate the initial step and return all observed values. However, the inputs are not reset therefore. Parameters ---------- seed : int, optional The seed is not used for the FMU since its calculations are deterministic but could be used by the user e.g. for weather models interacting with the FMU during the simulation. \"\"\" if self . reset_inputs : # set all inputs to zero for consistent simulation results for x in self . fmu . input : self . fmu . fmu . setReal ([ x . valueReference ], [ 0 ]) # get the first observation as specified by gymnaisum self . _next_observation ( steps = 1 ) return self . obs_processing ( self . outputs [ self . step_count , :])","title":"Parameters"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.set_action_space","text":"Setter function for the action space of the agent. As default, the action space is defined with respect to the loaded FMU and uses all inputs as actions. For other (restricted) action spaces, this function needs to be modified. For information about possible space definitions, see https://gymnasium.farama.org/api/spaces/.","title":"set_action_space"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.set_action_space--returns","text":"space : gymnasium.space Returns the unbounded action space defined by the FMU inputs Source code in src/stableRLS/gymFMU.py 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 def set_action_space ( self ): \"\"\"Setter function for the action space of the agent. As default, the action space is defined with respect to the loaded FMU and uses all inputs as actions. For other (restricted) action spaces, this function needs to be modified. For information about possible space definitions, see https://gymnasium.farama.org/api/spaces/. Returns ------- space : gymnasium.space Returns the unbounded action space defined by the FMU inputs \"\"\" high = np . arange ( len ( self . fmu . input )) . astype ( np . float32 ) high [:] = np . inf low = high * - 1 return gym . spaces . Box ( low , high )","title":"Returns"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.set_observation_space","text":"Setter function for the observation space of the agent. As default, the action space is defined with respect to the loaded FMU and uses all outputs as observations. For other (restricted) observation spaces, this function needs to be modified. For information about possible space definitions, see https://gymnasium.farama.org/api/spaces/.","title":"set_observation_space"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.set_observation_space--returns","text":"space : gymnasium.space Returns the unbounded observation space defined by the FMU outputs Source code in src/stableRLS/gymFMU.py 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 def set_observation_space ( self ): \"\"\"Setter function for the observation space of the agent. As default, the action space is defined with respect to the loaded FMU and uses all outputs as observations. For other (restricted) observation spaces, this function needs to be modified. For information about possible space definitions, see https://gymnasium.farama.org/api/spaces/. Returns ------- space : gymnasium.space Returns the unbounded observation space defined by the FMU outputs \"\"\" high = np . arange ( len ( self . fmu . output )) . astype ( np . float32 ) high [:] = np . inf low = high * - 1 return gym . spaces . Box ( low , high )","title":"Returns"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.step","text":"Run one time step of the environment's dynamics using the agent actions. (Adapted from gymnasium documentation v0.28.1)","title":"step"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.step--parameters","text":"action : list An action provided by the agent to update the environment state.","title":"Parameters"},{"location":"source/gymFMU/#stableRLS.gymFMU.StableRLS.step--returns","text":"observation : ObsType An element of the environment's observation_space as the next observation due to the agent actions. An example is a numpy array containing the positions and velocities of the pole in CartPole. reward : SupportsFloat The reward as a result of taking the action. terminated : bool Whether the agent reaches the terminal state (as defined under the MDP of the task) which can be positive or negative. An example is reaching the goal state or moving into the lava from the Sutton and Barton, Gridworld. If true, the user needs to call :meth: reset . truncated : bool Whether the truncation condition outside the scope of the MDP is satisfied. Typically, this is a timelimit, but could also be used to indicate an agent physically going out of bounds. Can be used to end the episode prematurely before a terminal state is reached. If true, the user needs to call :meth: reset . info : dict Contains auxiliary diagnostic information (helpful for debugging, learning, and logging). This might, for instance, contain: metrics that describe the agent's performance state, variables that are hidden from observations, or individual reward terms that are combined to produce the total reward. In OpenAI Gym <v26, it contains \"TimeLimit.truncated\" to distinguish truncation and termination, however this is deprecated in favor of returning terminated and truncated variables. Source code in src/stableRLS/gymFMU.py 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 def step ( self , action ): \"\"\"Run one time step of the environment's dynamics using the agent actions. (Adapted from gymnasium documentation v0.28.1) Parameters ---------- action : list An action provided by the agent to update the environment state. Returns ---------- observation : ObsType An element of the environment's `observation_space` as the next observation due to the agent actions. An example is a numpy array containing the positions and velocities of the pole in CartPole. reward : SupportsFloat The reward as a result of taking the action. terminated : bool Whether the agent reaches the terminal state (as defined under the MDP of the task) which can be positive or negative. An example is reaching the goal state or moving into the lava from the Sutton and Barton, Gridworld. If true, the user needs to call :meth:`reset`. truncated : bool Whether the truncation condition outside the scope of the MDP is satisfied. Typically, this is a timelimit, but could also be used to indicate an agent physically going out of bounds. Can be used to end the episode prematurely before a terminal state is reached. If true, the user needs to call :meth:`reset`. info : dict Contains auxiliary diagnostic information (helpful for debugging, learning, and logging). This might, for instance, contain: metrics that describe the agent's performance state, variables that are hidden from observations, or individual reward terms that are combined to produce the total reward. In OpenAI Gym <v26, it contains \"TimeLimit.truncated\" to distinguish truncation and termination, however this is deprecated in favor of returning terminated and truncated variables. \"\"\" # make sure we have a float32 numpy array action = np . array ( action ) . astype ( np . float32 ) # assign actions to FMU input self . assignAction ( action ) # simulate next step(s) of the FMU self . _next_observation () # get observation vector / outputs of the FMU observation = self . obs_processing ( self . outputs [ self . step_count , :]) # calculate rewards and if needed set truncated flag reward , terminated , truncated , info = self . get_reward ( action , observation ) # end of simulation time reached? if self . time > self . stop_time + 0.5 * self . dt : truncated = True logger . info ( \"Simulation done\" ) return observation , reward , terminated , truncated , info","title":"Returns"},{"location":"source/install/","text":"Installation StableRLS StableRLS is a software package that lets you use your existing MATLAB Simulink models in Python for reinforcement learning. Basically, your simulation is wrapped in a Python Gymnasium environment. The package provides the following features: - automatic generation of input and output signals for your model - automatic compilation of the Simulink model into a functional-mockup-unit (FMU) to enable fast simulation - flexible post-processing implementation - easy-to-read code And the best part is that the only thing you need to do is: - define a reward function to train your agent General Information Reinforcement Learning (RL) is a rapidly changing and innovative field. The main purpose of this package is to combine the easy-to-use MATLAB Simulink modeling interface with the flexible and state-of-the-art Gymnasium interface. Therefore, the RL algorithm and the learning interface are out of scope for this package. However, we make the interface between Matlab and Python as easy as possible. Installation Steps This package is currently tested with Python 3.9. To install the package, run pip install StableRLS . You have to install the MATLAB engine separately because each MATLAB release has some specific requirements (see below). You can also clone this repository and run pip install -e StableRLS/ from the main directory. This will also install the main dependencies, which are listed in requirements.txt . To actively contribute, you should also install the optional-requirements.txt , which also includes the dependencies for building the documentation, by running pip install -r optional-requirements.txt . We decided to exclude the typical machine learning frameworks (PyTorch, Tensorflow) from the requirements, because everyone has their own preferences and we want to keep this package small. But some of our examples are based on PyTorch, so you need to run pip install torch if you want to run them locally. This will also be mentioned in the examples. To compile the documentation locally, you need to have Pandoc installed on your computer. Matlab Version The MATLAB engine Python package is a requirement to compile a given MATLAB Simulink model. Before the MATLAB release R2022b it was inconvenient to install the engine, see the instructions . After the release, it's possible to install the engine as a pip package. StableRLS won't try to install the MATLAB engine as dependency because the pip package only supports the newest MATLAB release. Currently, you can run pip install matlabengine if you have MATLAB 2023a installed, if you have MATLAB 2022b installed run pip install matlabengine==9.13.7 . For other releases refer to the documentation mentioned. Get Started Check out our examples (/examples) or the documentation, which also contains the examples.","title":"Installation"},{"location":"source/install/#installation","text":"","title":"Installation"},{"location":"source/install/#stablerls","text":"StableRLS is a software package that lets you use your existing MATLAB Simulink models in Python for reinforcement learning. Basically, your simulation is wrapped in a Python Gymnasium environment. The package provides the following features: - automatic generation of input and output signals for your model - automatic compilation of the Simulink model into a functional-mockup-unit (FMU) to enable fast simulation - flexible post-processing implementation - easy-to-read code And the best part is that the only thing you need to do is: - define a reward function to train your agent","title":"StableRLS"},{"location":"source/install/#general-information","text":"Reinforcement Learning (RL) is a rapidly changing and innovative field. The main purpose of this package is to combine the easy-to-use MATLAB Simulink modeling interface with the flexible and state-of-the-art Gymnasium interface. Therefore, the RL algorithm and the learning interface are out of scope for this package. However, we make the interface between Matlab and Python as easy as possible.","title":"General Information"},{"location":"source/install/#installation-steps","text":"This package is currently tested with Python 3.9. To install the package, run pip install StableRLS . You have to install the MATLAB engine separately because each MATLAB release has some specific requirements (see below). You can also clone this repository and run pip install -e StableRLS/ from the main directory. This will also install the main dependencies, which are listed in requirements.txt . To actively contribute, you should also install the optional-requirements.txt , which also includes the dependencies for building the documentation, by running pip install -r optional-requirements.txt . We decided to exclude the typical machine learning frameworks (PyTorch, Tensorflow) from the requirements, because everyone has their own preferences and we want to keep this package small. But some of our examples are based on PyTorch, so you need to run pip install torch if you want to run them locally. This will also be mentioned in the examples. To compile the documentation locally, you need to have Pandoc installed on your computer.","title":"Installation Steps"},{"location":"source/install/#matlab-version","text":"The MATLAB engine Python package is a requirement to compile a given MATLAB Simulink model. Before the MATLAB release R2022b it was inconvenient to install the engine, see the instructions . After the release, it's possible to install the engine as a pip package. StableRLS won't try to install the MATLAB engine as dependency because the pip package only supports the newest MATLAB release. Currently, you can run pip install matlabengine if you have MATLAB 2023a installed, if you have MATLAB 2022b installed run pip install matlabengine==9.13.7 . For other releases refer to the documentation mentioned.","title":"Matlab Version"},{"location":"source/install/#get-started","text":"Check out our examples (/examples) or the documentation, which also contains the examples.","title":"Get Started"},{"location":"source/port_creation/","text":"Simulink Structure One main part of this package is the generation of bus structures for the inport and outport of the MATLAB Simulink model. Sadly, this is required for the model compilation. The function iterates recursively through the model and supports the following features: - \"Inport\" and \"Bus Element\" support - Goto Labels - Connections to multiple subsystems or blocks The function is also optimized to reduce the complexity of the bus structure by removing duplicate elements. However, MATLAB seems to have introduced some strange compilation dependencies, and the FMU compilation fails sometimes. To avoid this issue, it is recommended to wrap your whole system inside one subsystem on the top level and connect \"inports\" and \"outports\" to the connections. Your model should look something like this: Troubleshoot The MATLAB engine has some errors while running getports . This is related to existing bus definitions within the model. Simply run the following code to reset all signals to inherit: path = 'your_model_name' inports = find_system(path,'LookUnderMasks','on',... 'FollowLinks','on', 'BlockType','Inport'); outports = find_system(path,'LookUnderMasks','on',... 'FollowLinks','on', 'BlockType','Outport'); ports = cat(1, inports, outports); for i = 1 : length(ports) set_param(ports{i},'OutDataTypeStr','Inherit: auto'); end During the FMU compilation, the error The specified key is not present in this container occurs. This is related to internal MATLAB issues. Just pack your model inside a subsystem as mentioned above, and this should work.","title":"Port Creation"},{"location":"source/port_creation/#simulink-structure","text":"One main part of this package is the generation of bus structures for the inport and outport of the MATLAB Simulink model. Sadly, this is required for the model compilation. The function iterates recursively through the model and supports the following features: - \"Inport\" and \"Bus Element\" support - Goto Labels - Connections to multiple subsystems or blocks The function is also optimized to reduce the complexity of the bus structure by removing duplicate elements. However, MATLAB seems to have introduced some strange compilation dependencies, and the FMU compilation fails sometimes. To avoid this issue, it is recommended to wrap your whole system inside one subsystem on the top level and connect \"inports\" and \"outports\" to the connections. Your model should look something like this:","title":"Simulink Structure"},{"location":"source/port_creation/#troubleshoot","text":"The MATLAB engine has some errors while running getports . This is related to existing bus definitions within the model. Simply run the following code to reset all signals to inherit: path = 'your_model_name' inports = find_system(path,'LookUnderMasks','on',... 'FollowLinks','on', 'BlockType','Inport'); outports = find_system(path,'LookUnderMasks','on',... 'FollowLinks','on', 'BlockType','Outport'); ports = cat(1, inports, outports); for i = 1 : length(ports) set_param(ports{i},'OutDataTypeStr','Inherit: auto'); end During the FMU compilation, the error The specified key is not present in this container occurs. This is related to internal MATLAB issues. Just pack your model inside a subsystem as mentioned above, and this should work.","title":"Troubleshoot"}]}